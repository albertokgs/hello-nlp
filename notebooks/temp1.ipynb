{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d5920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for BRL=X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BRL=X']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "\n",
      "\n",
      "1 Failed download:\n",
      "['BRL=X']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Downloaded data is empty!\n",
      "Detected MultiIndex columns, flattening...\n",
      "Data shape after preprocessing: (0, 3)\n",
      "Date range: NaT to NaT\n",
      "Train data shape: (0, 1)\n",
      "Test data shape: (0, 1)\n",
      "Error: Train data is empty! Check the date slicing.\n",
      "Index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# Check index type\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIndex type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(df.index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIndex example: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Scale Data (Crucial for Neural Networks)\u001b[39;00m\n\u001b[32m     72\u001b[39m scaler = MinMaxScaler()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/lab/lib/python3.12/site-packages/pandas/core/indexes/base.py:5401\u001b[39m, in \u001b[36mIndex.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   5398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[32m   5399\u001b[39m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[32m   5400\u001b[39m     key = com.cast_scalar_indexer(key)\n\u001b[32m-> \u001b[39m\u001b[32m5401\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   5404\u001b[39m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[32m   5405\u001b[39m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[32m   5406\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_slice(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/lab/lib/python3.12/site-packages/pandas/core/arrays/datetimelike.py:398\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[33;03mThis getitem defers to the underlying array, which by-definition can\u001b[39;00m\n\u001b[32m    393\u001b[39m \u001b[33;03monly handle list-likes, slices, and integer scalars\u001b[39;00m\n\u001b[32m    394\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# Use cast as we know we will get back a DatetimeLikeArray or DTScalar,\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# but skip evaluating the Union at runtime for performance\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# (see https://github.com/pandas-dev/pandas/pull/44624)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m result = cast(\u001b[33m\"\u001b[39m\u001b[33mUnion[Self, DTScalarOrNaT]\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lib.is_scalar(result):\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/lab/lib/python3.12/site-packages/pandas/core/arrays/_mixins.py:284\u001b[39m, in \u001b[36mNDArrayBackedExtensionArray.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\n\u001b[32m    279\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    280\u001b[39m     key: PositionalIndexer2D,\n\u001b[32m    281\u001b[39m ) -> Self | Any:\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lib.is_integer(key):\n\u001b[32m    283\u001b[39m         \u001b[38;5;66;03m# fast-path\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ndarray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    285\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    286\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._box_func(result)\n",
      "\u001b[31mIndexError\u001b[39m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Force CPU usage to avoid macOS Metal/GPU crashes\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "try:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "\n",
    "# --- 1. Get Data (USD/BRL) ---\n",
    "# We download daily data.\n",
    "ticker = 'BRL=X'\n",
    "print(f\"Downloading data for {ticker}...\")\n",
    "df_raw = yf.download(ticker, start='2021-01-01', end='2025-11-28')\n",
    "\n",
    "if df_raw.empty:\n",
    "    print(\"Error: Downloaded data is empty! (Likely Rate Limit)\")\n",
    "    print(\"Generating SYNTHETIC data to verify TensorFlow environment...\")\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    dates = pd.date_range(start='2021-01-01', end='2025-11-28', freq='D')\n",
    "    np.random.seed(42)\n",
    "    # Random walk\n",
    "    steps = np.random.normal(loc=0.0001, scale=0.01, size=len(dates))\n",
    "    price_path = 100 * np.exp(np.cumsum(steps))\n",
    "    \n",
    "    df_raw = pd.DataFrame(price_path, index=dates, columns=['Close'])\n",
    "    print(f\"Generated synthetic data shape: {df_raw.shape}\")\n",
    "else:\n",
    "    print(f\"Downloaded data shape: {df_raw.shape}\")\n",
    "    print(df_raw.head())\n",
    "\n",
    "# Handle potential MultiIndex columns from yfinance\n",
    "if isinstance(df_raw.columns, pd.MultiIndex):\n",
    "    print(\"Detected MultiIndex columns, flattening...\")\n",
    "    try:\n",
    "        data = df_raw['Close']\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "             data = data.iloc[:, 0] # Take the first column if it's still a DF\n",
    "    except KeyError:\n",
    "        print(\"KeyError: 'Close' not found in columns\")\n",
    "        print(df_raw.columns)\n",
    "        data = df_raw.iloc[:, 0] # Fallback\n",
    "else:\n",
    "    data = df_raw['Close']\n",
    "\n",
    "# Feature Engineering: We use Volatility (rolling std dev) as the feature\n",
    "# because regimes are often defined by volatility shifts, not just price levels.\n",
    "window_size = 30\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['Close']  # Ensure column name is set\n",
    "df['Returns'] = df['Close'].pct_change()\n",
    "df['Vol'] = df['Returns'].rolling(window=5).std() # 5-day rolling vol\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(f\"Data shape after preprocessing: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "\n",
    "# Split into Training (Normal Regime) and Testing (Unknown/Potential New Regimes)\n",
    "train_end = '2024-06-30'\n",
    "train_data = df.loc[:train_end, ['Vol']]\n",
    "test_data = df.loc[train_end:, ['Vol']]\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "if train_data.empty:\n",
    "    print(\"Error: Train data is empty! Check the date slicing.\")\n",
    "    # Check index type\n",
    "    print(f\"Index type: {type(df.index)}\")\n",
    "    if len(df.index) > 0:\n",
    "        print(f\"Index example: {df.index[0]}\")\n",
    "else:\n",
    "    # Scale Data (Crucial for Neural Networks)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_data)\n",
    "    train_scaled = scaler.transform(train_data)\n",
    "    test_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # --- 2. Create Sequences (LSTM requires 3D input: [Samples, Timesteps, Features]) ---\n",
    "    def create_sequences(data, steps=30):\n",
    "       sequences = []\n",
    "       for i in range(len(data) - steps):\n",
    "           sequences.append(data[i:(i + steps)])\n",
    "       return np.array(sequences)\n",
    "\n",
    "    TIME_STEPS = 30\n",
    "    X_train = create_sequences(train_scaled, TIME_STEPS)\n",
    "    X_test = create_sequences(test_scaled, TIME_STEPS)\n",
    "\n",
    "    # --- 3. Build the LSTM Autoencoder ---\n",
    "    model = Sequential([\n",
    "       # Encoder: Compresses the 30-day sequence into a small vector\n",
    "       LSTM(16, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),\n",
    "\n",
    "       # The \"Latent Space\" (Compressed Representation)\n",
    "       RepeatVector(X_train.shape[1]),\n",
    "\n",
    "       # Decoder: Unpacks the vector back into the 30-day sequence\n",
    "       LSTM(16, activation='relu', return_sequences=True),\n",
    "       TimeDistributed(Dense(X_train.shape[2]))\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    print(\"Starting model training...\")\n",
    "    model.fit(X_train, X_train, epochs=5, batch_size=32, validation_split=0.1, verbose=1)\n",
    "    print(\"Model training completed successfully!\")\n",
    "\n",
    "    # --- 4. Detect Regimes (Calculate Reconstruction Error) ---\n",
    "    # We ask the model to reconstruct the Test data (Jul 2024+)\n",
    "    X_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE) for each day\n",
    "    test_mae_loss = np.mean(np.abs(X_test_pred - X_test), axis=1)\n",
    "\n",
    "    # Create a DataFrame for plotting\n",
    "    test_score_df = pd.DataFrame(index=test_data[TIME_STEPS:].index)\n",
    "    test_score_df['loss'] = test_mae_loss\n",
    "    test_score_df['threshold'] = 0.15  # Set a manual threshold for visual clarity\n",
    "    test_score_df['Close'] = df.loc[test_score_df.index]['Close']\n",
    "\n",
    "    # --- 5. Visualization ---\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plot 1: The Reconstruction Error (The \"Regime Signal\")\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(test_score_df.index, test_score_df['loss'], label='Reconstruction Error', color='red')\n",
    "    plt.axhline(y=0.15, color='black', linestyle='--', label='Regime Threshold')\n",
    "    plt.title('Regime Detection: Reconstruction Error (Higher = Unknown Regime)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot 2: The Actual Price (USDBRL)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(test_score_df.index, test_score_df['Close'], label='USDBRL Price', color='blue')\n",
    "    plt.title('Actual USDBRL Price')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
